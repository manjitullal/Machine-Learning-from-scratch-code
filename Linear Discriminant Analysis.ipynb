{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there are more than 2 classes a better approach to classify them is to use LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why do do we need another method?\n",
    "\n",
    "problems with logistic regression \n",
    "\n",
    "a) unstable when the classes are well separated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two different approches to do LDA, the one approach showed below is the Bayesian approach which assumes that the data within each class is normally distributed, the other approach is Fisher LDA \n",
    "\n",
    "https://stats.stackexchange.com/questions/87975/bayesian-and-fishers-approaches-to-linear-discriminant-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### the key Assumption\n",
    "\n",
    "data for each class is normally distributed and \n",
    "\n",
    "in order to run the LDA we want the classes to have same variance\n",
    "\n",
    "https://stats.stackexchange.com/questions/71489/three-versions-of-discriminant-analysis-differences-and-how-to-use-them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given the data we find what is probability that the data belongs to kth class \n",
    "\n",
    "$$P_r(Y = k|X = x) = \\frac{\\pi_k * f_k(x)} {\\sum_{n=1}^{K} \\pi_l * f_l(x)}$$\n",
    "\n",
    "we know the prior probability and that the data within is normally distributed which is described by a PDF, using this in a Bayes theorem we get the posterior \n",
    "\n",
    "Given an observation, we will calculate the probability, that the observation belongs to one of the classes and then assign the class which has the highest probabiltity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LDA and PCA are related, so before doing LDA it is better to learn the PCA and the implementation.\n",
    "The implemetation of LDA is mostly the fisher LDA, which requires the principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### why LDA may overfit\n",
    "\n",
    "https://stats.stackexchange.com/questions/108928/is-linear-discriminant-analysis-lda-more-likely-to-overfit-than-support-vector\n",
    "\n",
    "https://stats.stackexchange.com/questions/306526/why-linear-discriminant-analysis-is-sensitive-to-cross-validation-lda-overfit-p/306729\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal_length</th>\n",
       "      <th>Sepal_Width</th>\n",
       "      <th>Petal_length</th>\n",
       "      <th>Petal_Width</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sepal_length  Sepal_Width  Petal_length  Petal_Width           Class\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"iris.data\",sep=\",\",names=[\"Sepal_length\",\"Sepal_Width\",\"Petal_length\",\"Petal_Width\",\"Class\"])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = df.iloc[:,0:4]\n",
    "y = df['Class'].values\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_label = encoder.fit(y)\n",
    "y_encoded = y_label.transform(y)+1\n",
    "\n",
    "label_dict = {1: 'Setosa', 2: 'Versicolor', 3:'Virginica'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### feature selection approaches\n",
    "\n",
    "1. filter method (manual selection by evalutaing using the metrics like fisher score, chi-square, correlation coefficient etc)\n",
    "\n",
    "2. wrapper method (use algorithm such has subset selection)\n",
    "\n",
    "3. Embedded method (use L1 or L2 regularization)\n",
    "\n",
    "referenced from\n",
    "\n",
    "https://sebastianraschka.com/faq/docs/feature_sele_categories.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA for classifier requires normally distributed data and identical covariance matrices for every class, however LDA will still work well for dimension reduction regardless of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Steps\n",
    "\n",
    "This looks same as PCA\n",
    "\n",
    "1. find the mean of all the classes\n",
    "2. find the scatter matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the mean\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "all_mean = []\n",
    "for i in range(1,4):\n",
    "    all_mean.append(np.mean(X[y_encoded==i] , axis=0))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sepal_length    5.006\n",
       " Sepal_Width     3.418\n",
       " Petal_length    1.464\n",
       " Petal_Width     0.244\n",
       " dtype: float64, Sepal_length    5.936\n",
       " Sepal_Width     2.770\n",
       " Petal_length    4.260\n",
       " Petal_Width     1.326\n",
       " dtype: float64, Sepal_length    6.588\n",
       " Sepal_Width     2.974\n",
       " Petal_length    5.552\n",
       " Petal_Width     2.026\n",
       " dtype: float64]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-c739b4083761>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Sepal_length\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Sepal_Width\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Petal_length\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Petal_Width\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# make column vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mclass_sc_mat\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mscatter_matrix\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mclass_sc_mat\u001b[0m                             \u001b[1;31m# sum class scatter matrices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5178\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5179\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "#within class scatter matrix \n",
    "\n",
    "scatter_matrix = np.zeros((4,4))\n",
    "for cl,mv in zip(range(1,4), all_mean):\n",
    "    class_sc_mat = np.zeros((4,4))                  # scatter matrix for every class\n",
    "    df2 = X[y_encoded == cl]\n",
    "    for i,j in df2.iterrows():\n",
    "        row = np.array([j[\"Sepal_length\"],j[\"Sepal_Width\"],j[\"Petal_length\"],j[\"Petal_Width\"]])\n",
    "        print(type(row),type(mv))\n",
    "        row, mv = row.reshape(4,1), mv.reshape(4,1) # make column vectors\n",
    "        class_sc_mat += (row-mv).dot((row-mv).T)\n",
    "    scatter_matrix += class_sc_mat                             # sum class scatter matrices\n",
    "scatter_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.1 3.5 1.4 0.2]\n",
      "[4.9 3.  1.4 0.2]\n",
      "[4.7 3.2 1.3 0.2]\n",
      "[4.6 3.1 1.5 0.2]\n",
      "[5.  3.6 1.4 0.2]\n",
      "[5.4 3.9 1.7 0.4]\n",
      "[4.6 3.4 1.4 0.3]\n",
      "[5.  3.4 1.5 0.2]\n",
      "[4.4 2.9 1.4 0.2]\n",
      "[4.9 3.1 1.5 0.1]\n",
      "[5.4 3.7 1.5 0.2]\n",
      "[4.8 3.4 1.6 0.2]\n",
      "[4.8 3.  1.4 0.1]\n",
      "[4.3 3.  1.1 0.1]\n",
      "[5.8 4.  1.2 0.2]\n",
      "[5.7 4.4 1.5 0.4]\n",
      "[5.4 3.9 1.3 0.4]\n",
      "[5.1 3.5 1.4 0.3]\n",
      "[5.7 3.8 1.7 0.3]\n",
      "[5.1 3.8 1.5 0.3]\n",
      "[5.4 3.4 1.7 0.2]\n",
      "[5.1 3.7 1.5 0.4]\n",
      "[4.6 3.6 1.  0.2]\n",
      "[5.1 3.3 1.7 0.5]\n",
      "[4.8 3.4 1.9 0.2]\n",
      "[5.  3.  1.6 0.2]\n",
      "[5.  3.4 1.6 0.4]\n",
      "[5.2 3.5 1.5 0.2]\n",
      "[5.2 3.4 1.4 0.2]\n",
      "[4.7 3.2 1.6 0.2]\n",
      "[4.8 3.1 1.6 0.2]\n",
      "[5.4 3.4 1.5 0.4]\n",
      "[5.2 4.1 1.5 0.1]\n",
      "[5.5 4.2 1.4 0.2]\n",
      "[4.9 3.1 1.5 0.1]\n",
      "[5.  3.2 1.2 0.2]\n",
      "[5.5 3.5 1.3 0.2]\n",
      "[4.9 3.1 1.5 0.1]\n",
      "[4.4 3.  1.3 0.2]\n",
      "[5.1 3.4 1.5 0.2]\n",
      "[5.  3.5 1.3 0.3]\n",
      "[4.5 2.3 1.3 0.3]\n",
      "[4.4 3.2 1.3 0.2]\n",
      "[5.  3.5 1.6 0.6]\n",
      "[5.1 3.8 1.9 0.4]\n",
      "[4.8 3.  1.4 0.3]\n",
      "[5.1 3.8 1.6 0.2]\n",
      "[4.6 3.2 1.4 0.2]\n",
      "[5.3 3.7 1.5 0.2]\n",
      "[5.  3.3 1.4 0.2]\n"
     ]
    }
   ],
   "source": [
    "df2 = X[y_encoded == 1]\n",
    "for i,j in df2.iterrows():\n",
    "    print(np.array([j[\"Sepal_length\"],j[\"Sepal_Width\"],j[\"Petal_length\"],j[\"Petal_Width\"]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The implementation has been taken from \n",
    "\n",
    "https://sebastianraschka.com/Articles/2014_python_lda.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Detour \n",
    "\n",
    "why is it required that the residuals are normally distributed for Linear Regression ?\n",
    "\n",
    "this is needed because this means for different values of the input the model is consistently giving the output, if this is not true then this means that the model is selecting giving values to one type of input over other.\n",
    "\n",
    "the amount of error in your model is consistent across the full range of your observed data.\n",
    "\n",
    "https://www.researchgate.net/post/Why_do_the_residuals_need_to_be_normal_when_carrying_out_multi_level_modeling\n",
    "https://stats.stackexchange.com/questions/12262/what-if-residuals-are-normally-distributed-but-y-is-not\n",
    "\n",
    "we can use f string in python, which is cool. Checkout below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Manjit\"\n",
    "text = f\"Hello {name}\" #just write f next to the string and then use the variable name\n",
    "text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
